{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b9fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, threading, queue, time, json, re\n",
    "import numpy as np\n",
    "import torch\n",
    "import sounddevice as sd\n",
    "import whisper\n",
    "\n",
    "from helper_functions import create_bold_stickman, load_gt_landmarks, sanitize_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56de727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default input device index : 1\n",
      "Default output device index: 3\n"
     ]
    }
   ],
   "source": [
    "default_in, default_out = sd.default.device\n",
    "print(f\"Default input device index : {default_in}\")\n",
    "print(f\"Default output device index: {default_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61b4569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All audio devices:\n",
      " 0: Microsoft Sound Mapper - Input — 0 — max_in:2  max_out:0\n",
      " 1: Microphone (HD Webcam eMeet C96 — 0 — max_in:2  max_out:0\n",
      " 2: Microsoft Sound Mapper - Output — 0 — max_in:0  max_out:2\n",
      " 3: Speakers (Realtek High Definiti — 0 — max_in:0  max_out:8\n",
      " 4: ES-G27F2Q (NVIDIA High Definiti — 0 — max_in:0  max_out:2\n",
      " 5: H24V13 (NVIDIA High Definition  — 0 — max_in:0  max_out:2\n",
      " 6: Realtek Digital Output (Realtek — 0 — max_in:0  max_out:2\n",
      " 7: Primary Sound Capture Driver — 1 — max_in:2  max_out:0\n",
      " 8: Microphone (HD Webcam eMeet C960) — 1 — max_in:2  max_out:0\n",
      " 9: Primary Sound Driver — 1 — max_in:0  max_out:2\n",
      "10: Speakers (Realtek High Definition Audio) — 1 — max_in:0  max_out:8\n",
      "11: ES-G27F2Q (NVIDIA High Definition Audio) — 1 — max_in:0  max_out:2\n",
      "12: H24V13 (NVIDIA High Definition Audio) — 1 — max_in:0  max_out:2\n",
      "13: Realtek Digital Output (Realtek High Definition Audio) — 1 — max_in:0  max_out:2\n",
      "14: Speakers (Realtek High Definition Audio) — 2 — max_in:0  max_out:2\n",
      "15: ES-G27F2Q (NVIDIA High Definition Audio) — 2 — max_in:0  max_out:2\n",
      "16: H24V13 (NVIDIA High Definition Audio) — 2 — max_in:0  max_out:2\n",
      "17: Realtek Digital Output (Realtek High Definition Audio) — 2 — max_in:0  max_out:2\n",
      "18: Microphone (HD Webcam eMeet C960) — 2 — max_in:2  max_out:0\n",
      "19: Output (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Kevin's S23 Ultra)) — 3 — max_in:0  max_out:1\n",
      "20: Input (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Kevin's S23 Ultra)) — 3 — max_in:1  max_out:0\n",
      "21: Stereo Mix (Realtek HD Audio Stereo input) — 3 — max_in:2  max_out:0\n",
      "22: Line In (Realtek HD Audio Line input) — 3 — max_in:2  max_out:0\n",
      "23: Speakers (Realtek HD Audio output) — 3 — max_in:0  max_out:8\n",
      "24: Microphone (Realtek HD Audio Mic input) — 3 — max_in:2  max_out:0\n",
      "25: SPDIF Out (Realtek HDA SPDIF Out) — 3 — max_in:0  max_out:2\n",
      "26: Output (NVIDIA High Definition Audio) — 3 — max_in:0  max_out:2\n",
      "27: Output () — 3 — max_in:0  max_out:2\n",
      "28: Headphones () — 3 — max_in:0  max_out:2\n",
      "29: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(WH-1000XM5)) — 3 — max_in:0  max_out:1\n",
      "30: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(WH-1000XM5)) — 3 — max_in:1  max_out:0\n",
      "31: Microphone (HD Webcam eMeet C960) — 3 — max_in:2  max_out:0\n",
      "32: Input () — 3 — max_in:2  max_out:0\n"
     ]
    }
   ],
   "source": [
    "# 2) List all devices, with their indices\n",
    "print(\"\\nAll audio devices:\")\n",
    "for idx, dev in enumerate(sd.query_devices()):\n",
    "    print(f\"{idx:>2}: {dev['name']} — {dev['hostapi']} — max_in:{dev['max_input_channels']}  max_out:{dev['max_output_channels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4211ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_land = load_gt_landmarks(\"landmark_data\")\n",
    "if \"no\" not in gt_land:\n",
    "    raise RuntimeError(\"You must have a 'no.json' in landmark_data for missing-word fallback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5fc41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————————————\n",
    "# 2) Set up Whisper tiny model on GPU if possible\n",
    "# —————————————————————————————————————————————\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model  = whisper.load_model(\"tiny\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb59902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “Hello.”\n",
      "[DEBUG] enqueue word: hello\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “work.”\n",
      "[DEBUG] enqueue word: work\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “animal.”\n",
      "[DEBUG] enqueue word: animal\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “question.”\n",
      "[DEBUG] enqueue word: question\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n",
      "[DEBUG] Transcribing 16000 samples…\n",
      "[DEBUG] Whisper returned: “”\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# —————————————————————————————————————————————\n",
    "#  Audio / word queues & constants\n",
    "# —————————————————————————————————————————————\n",
    "audio_q = queue.Queue()\n",
    "word_q  = queue.Queue()\n",
    "\n",
    "SAMPLERATE = 16000\n",
    "BLOCK_SIZE = SAMPLERATE  # 1 s blocks\n",
    "OVERLAP    = int(SAMPLERATE * 0.2)  # 0.2 s overlap\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"Convert CFFI buffer → int16 numpy → enqueue.\"\"\"\n",
    "    if status:\n",
    "        print(\"Audio status:\", status)\n",
    "    arr = np.frombuffer(indata, dtype=np.int16).reshape(frames, 1)\n",
    "    audio_q.put(arr)\n",
    "\n",
    "def audio_worker():\n",
    "    \"\"\"Normalize, sliding buffer, transcribe, flush queue, enqueue newest word.\"\"\"\n",
    "    buffer = np.empty((0,), dtype=np.float32)\n",
    "    while True:\n",
    "        chunk = audio_q.get()\n",
    "        if chunk is None:\n",
    "            break\n",
    "\n",
    "        # int16 → float32 in [-1,1]\n",
    "        f32 = chunk[:,0].astype(np.float32) / 32768.0\n",
    "        buffer = np.concatenate([buffer, f32])\n",
    "\n",
    "        if len(buffer) >= SAMPLERATE:\n",
    "            segment = buffer[:SAMPLERATE]\n",
    "            # keep last OVERLAP samples for next round\n",
    "            buffer = buffer[-OVERLAP:]\n",
    "\n",
    "            print(f\"[DEBUG] Transcribing {segment.shape[0]} samples…\")\n",
    "            result = model.transcribe(segment, word_timestamps=False)\n",
    "            text   = result[\"text\"].strip()\n",
    "            print(f\"[DEBUG] Whisper returned: “{text}”\")\n",
    "\n",
    "            for tok in text.split():\n",
    "                w = sanitize_word(tok)\n",
    "                if not w:\n",
    "                    continue\n",
    "\n",
    "                # flush older words\n",
    "                try:\n",
    "                    while True:\n",
    "                        word_q.get_nowait()\n",
    "                except queue.Empty:\n",
    "                    pass\n",
    "\n",
    "                word_q.put(w)\n",
    "                print(f\"[DEBUG] enqueue word: {w}\")\n",
    "\n",
    "# start audio stream + worker thread\n",
    "stream = sd.RawInputStream(\n",
    "    samplerate=SAMPLERATE,\n",
    "    blocksize=BLOCK_SIZE,\n",
    "    dtype=\"int16\",\n",
    "    channels=1,\n",
    "    callback=audio_callback\n",
    ")\n",
    "stream.start()\n",
    "t_audio = threading.Thread(target=audio_worker, daemon=True)\n",
    "t_audio.start()\n",
    "\n",
    "# —————————————————————————————————————————————\n",
    "# Webcam loop with overlay\n",
    "# —————————————————————————————————————————————\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open webcam\")\n",
    "\n",
    "current_word   = None\n",
    "display_text   = \"\"\n",
    "sequence       = []\n",
    "seq_idx        = 0\n",
    "\n",
    "FPS   = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "DELAY = int(1000 / FPS)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # pull fresh word if available\n",
    "    try:\n",
    "        w = word_q.get_nowait()\n",
    "    except queue.Empty:\n",
    "        w = None\n",
    "\n",
    "    if w:\n",
    "        current_word = w\n",
    "        if w in gt_land:\n",
    "            sequence = gt_land[w]\n",
    "            display_text = w\n",
    "        else:\n",
    "            sequence = gt_land[\"no\"]\n",
    "            display_text = f\"{w} not found\"\n",
    "        seq_idx = 0\n",
    "\n",
    "    # draw stickman if we have a sequence\n",
    "    if sequence:\n",
    "        flm = sequence[seq_idx % len(sequence)]\n",
    "        seq_idx += 1\n",
    "\n",
    "        ov = create_bold_stickman(flm, width=300, height=300)\n",
    "\n",
    "        H, W = frame.shape[:2]\n",
    "        x_off = (W - 300) // 2\n",
    "        y_off = H - 300\n",
    "\n",
    "        alpha = ov[:, :, 3] / 255.0\n",
    "        for c in range(3):\n",
    "            frame[y_off:y_off+300, x_off:x_off+300, c] = (\n",
    "                alpha * ov[:, :, c] +\n",
    "                (1-alpha) * frame[y_off:y_off+300, x_off:x_off+300, c]\n",
    "            ).astype(np.uint8)\n",
    "\n",
    "        cv2.putText(\n",
    "            frame, display_text,\n",
    "            org=(x_off+5, y_off-10),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=1.0, color=(255,255,255),\n",
    "            thickness=2, lineType=cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "    cv2.imshow(\"Live ASL Translation\", frame)\n",
    "    if cv2.waitKey(DELAY) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# —————————————————————————————————————————————\n",
    "# Cleanup\n",
    "# —————————————————————————————————————————————\n",
    "stream.stop()\n",
    "audio_q.put(None)\n",
    "t_audio.join()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_to_asl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
