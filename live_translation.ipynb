{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b9fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, threading, queue\n",
    "import numpy as np\n",
    "import torch\n",
    "import sounddevice as sd\n",
    "import whisper\n",
    "import time\n",
    "\n",
    "from helper_functions import create_bold_stickman, load_gt_landmarks, sanitize_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56de727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default input device index : 1\n",
      "Default output device index: 3\n"
     ]
    }
   ],
   "source": [
    "default_in, default_out = sd.default.device\n",
    "print(f\"Default input device index : {default_in}\")\n",
    "print(f\"Default output device index: {default_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e50b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILLER_WORDS = {\n",
    "    # articles & determiners\n",
    "    \"a\", \"an\", \"the\",\n",
    "    # to‑be verbs\n",
    "    \"is\", \"are\", \"am\", \"was\", \"were\", \"be\", \"being\", \"been\",\n",
    "    # conjunctions & prepositions\n",
    "    \"and\", \"or\", \"but\", \"so\", \"of\", \"to\", \"in\", \"for\", \"on\", \"at\", \"by\",\n",
    "    # common disfluencies\n",
    "    \"um\", \"uh\", \"like\", \"you\", \"know\", \"okay\", \"right\", \"i\", \"mean\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4211ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_land = load_gt_landmarks(\"landmark_data\")\n",
    "if \"no\" not in gt_land:\n",
    "    raise RuntimeError(\"You must have a 'no.json' in landmark_data for missing-word fallback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5fc41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————————————\n",
    "# 2) Set up Whisper tiny model on GPU if possible\n",
    "# —————————————————————————————————————————————\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model  = whisper.load_model(\"tiny\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb59902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] enqueue 'after' @ 1746165211.496\n",
      "[DEBUG] enqueue 'now' @ 1746165211.496\n",
      "[DEBUG] display 'now' latency=243.7ms\n",
      "[DEBUG] enqueue 'good' @ 1746165222.494\n",
      "[DEBUG] display 'good' latency=114.7ms\n",
      "[DEBUG] enqueue 'funny' @ 1746165236.496\n",
      "[DEBUG] display 'funny' latency=526.4ms\n",
      "[DEBUG] enqueue 'problem' @ 1746165255.495\n",
      "[DEBUG] display 'problem' latency=151.5ms\n",
      "Latency stats (ms):\n",
      "  min: 114.7\n",
      "  avg: 259.1\n",
      "  max: 526.4\n"
     ]
    }
   ],
   "source": [
    "# —————————————————————————————————————————————\n",
    "# 2) Audio / word queues & latency tracking\n",
    "# —————————————————————————————————————————————\n",
    "audio_q   = queue.Queue()\n",
    "word_q    = queue.Queue()\n",
    "LATENCIES = []  # list of floats\n",
    "\n",
    "SAMPLERATE = 16000\n",
    "BLOCK_SIZE = SAMPLERATE        # 1s blocks\n",
    "OVERLAP    = int(0.2*SAMPLERATE)  # 0.2s overlap\n",
    "\n",
    "def audio_callback(indata, frames, time_info, status):\n",
    "    if status:\n",
    "        print(\"Audio status:\", status)\n",
    "    arr = np.frombuffer(indata, dtype=np.int16).reshape(frames,1)\n",
    "    audio_q.put(arr)\n",
    "\n",
    "def audio_worker():\n",
    "    buffer = np.empty((0,), dtype=np.float32)\n",
    "    while True:\n",
    "        chunk = audio_q.get()\n",
    "        if chunk is None:\n",
    "            break\n",
    "        f32 = chunk[:,0].astype(np.float32)/32768.0\n",
    "        buffer = np.concatenate([buffer, f32])\n",
    "        if len(buffer) >= SAMPLERATE:\n",
    "            segment = buffer[:SAMPLERATE]\n",
    "            buffer  = buffer[-OVERLAP:]\n",
    "            t0 = time.time()\n",
    "            result = model.transcribe(segment, word_timestamps=False)\n",
    "            text   = result[\"text\"].strip()\n",
    "            for tok in text.split():\n",
    "                w = sanitize_word(tok)\n",
    "                if not w:\n",
    "                    continue\n",
    "                # flush old\n",
    "                while True:\n",
    "                    try: word_q.get_nowait()\n",
    "                    except queue.Empty: break\n",
    "                # enqueue with timestamp\n",
    "                word_q.put((w, t0))\n",
    "                print(f\"[DEBUG] enqueue '{w}' @ {t0:.3f}\")\n",
    "\n",
    "# start audio\n",
    "stream = sd.RawInputStream(\n",
    "    samplerate=SAMPLERATE, blocksize=BLOCK_SIZE,\n",
    "    dtype=\"int16\", channels=1, callback=audio_callback\n",
    ")\n",
    "stream.start()\n",
    "t_audio = threading.Thread(target=audio_worker, daemon=True)\n",
    "t_audio.start()\n",
    "\n",
    "# —————————————————————————————————————————————\n",
    "# 3) Webcam loop with latency overlay\n",
    "# —————————————————————————————————————————————\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open webcam\")\n",
    "\n",
    "FPS   = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "DELAY = int(1000/FPS)\n",
    "\n",
    "current_word = None\n",
    "display_text = \"\"\n",
    "sequence     = []\n",
    "seq_idx      = 0\n",
    "last_latency = 0.0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # grab any new word + its enqueue timestamp\n",
    "    try:\n",
    "        w, t_enqueue = word_q.get_nowait()\n",
    "        t_display = time.time()\n",
    "        last_latency = (t_display - t_enqueue)\n",
    "        LATENCIES.append(last_latency)\n",
    "        print(f\"[DEBUG] display '{w}' latency={last_latency*1000:.1f}ms\")\n",
    "\n",
    "        current_word = w\n",
    "        if w in gt_land:\n",
    "            sequence = gt_land[w]\n",
    "            display_text = w\n",
    "        else:\n",
    "            sequence = gt_land[\"no\"]\n",
    "            display_text = f\"{w} not found\"\n",
    "        seq_idx = 0\n",
    "    except queue.Empty:\n",
    "        pass\n",
    "\n",
    "    # draw stickman\n",
    "    if sequence:\n",
    "        flm = sequence[seq_idx % len(sequence)]\n",
    "        seq_idx += 1\n",
    "        ov = create_bold_stickman(flm, width=300, height=300)\n",
    "        H,W = frame.shape[:2]\n",
    "        x_off = (W-300)//2; y_off = H-300\n",
    "        alpha = ov[:,:,3]/255.0\n",
    "        for c in range(3):\n",
    "            frame[y_off:y_off+300, x_off:x_off+300, c] = (\n",
    "                alpha*ov[:,:,c] + (1-alpha)*frame[y_off:y_off+300,x_off:x_off+300,c]\n",
    "            ).astype(np.uint8)\n",
    "        cv2.putText(frame, display_text,\n",
    "                    (x_off+5, y_off-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,1.0,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "    # overlay latency in ms top-left\n",
    "    cv2.putText(frame, f\"Latency: {last_latency*1000:.1f} ms\",\n",
    "                (10,30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0),2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Live ASL Translation w/ Latency\", frame)\n",
    "    if cv2.waitKey(DELAY)&0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "# —————————————————————————————————————————————\n",
    "# 4) Cleanup & report stats\n",
    "# —————————————————————————————————————————————\n",
    "stream.stop()\n",
    "audio_q.put(None)\n",
    "t_audio.join()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if LATENCIES:\n",
    "    import statistics\n",
    "    print(\"Latency stats (ms):\")\n",
    "    print(f\"  min: {min(LATENCIES)*1000:.1f}\")\n",
    "    print(f\"  avg: {statistics.mean(LATENCIES)*1000:.1f}\")\n",
    "    print(f\"  max: {max(LATENCIES)*1000:.1f}\")\n",
    "else:\n",
    "    print(\"No latency samples collected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_to_asl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
